#!/usr/bin/env python3
"""
å®Ÿéš›ã«ä½¿ã‚ã‚Œã¦ã„ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç‰¹å®šã™ã‚‹ãƒ„ãƒ¼ãƒ«
ï¼ˆimportæ–‡ã‚’è¿½è·¡ï¼‰
"""
import ast
import os
from pathlib import Path
from collections import defaultdict

class ImportTracker:
    """importæ–‡ã‚’è¿½è·¡ã—ã¦ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¾å­˜é–¢ä¿‚ã‚’å¯è¦–åŒ–"""
    
    def __init__(self):
        self.root = Path(".")
        self.imports = defaultdict(set)  # ãƒ•ã‚¡ã‚¤ãƒ« -> importã—ã¦ã„ã‚‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
        self.imported_by = defaultdict(set)  # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« -> importã•ã‚Œã¦ã„ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«
        
    def analyze_imports(self, file_path):
        """1ã¤ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®importæ–‡ã‚’è§£æ"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                tree = ast.parse(f.read())
            
            imports = set()
            for node in ast.walk(tree):
                if isinstance(node, ast.Import):
                    for alias in node.names:
                        imports.add(alias.name)
                elif isinstance(node, ast.ImportFrom):
                    if node.module:
                        imports.add(node.module)
            
            return imports
        except:
            return set()
    
    def scan_project(self):
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…¨ä½“ã‚’ã‚¹ã‚­ãƒ£ãƒ³"""
        print("ğŸ” ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…¨ä½“ã®importæ–‡ã‚’ã‚¹ã‚­ãƒ£ãƒ³ä¸­...\n")
        
        for file in self.root.rglob("*.py"):
            if '__pycache__' in str(file):
                continue
            
            imports = self.analyze_imports(file)
            self.imports[str(file)] = imports
            
            # é€†å¼•ãè¾æ›¸ã‚‚ä½œæˆ
            for imp in imports:
                self.imported_by[imp].add(str(file))
    
    def find_entry_points(self):
        """ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆï¼ˆãƒ¡ã‚¤ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼‰ã‚’æ¤œå‡º"""
        print("=" * 80)
        print("ğŸš€ ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆï¼ˆå®Ÿè¡Œå¯èƒ½ãªãƒ¡ã‚¤ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰")
        print("=" * 80)
        
        entry_points = []
        
        for file in self.root.glob("*.py"):
            if file.name.startswith(('main_', 'run_', 'test_')):
                entry_points.append(file)
        
        for i, entry in enumerate(sorted(entry_points), 1):
            print(f"{i}. {entry}")
            
        return entry_points
    
    def trace_dependencies(self, entry_point):
        """ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰ä¾å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãŸã©ã‚‹"""
        visited = set()
        to_visit = [str(entry_point)]
        dependencies = []
        
        while to_visit:
            current = to_visit.pop(0)
            if current in visited:
                continue
            
            visited.add(current)
            dependencies.append(current)
            
            # ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒimportã—ã¦ã„ã‚‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
            imports = self.imports.get(current, set())
            
            # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’æ¢ã™
            for imp in imports:
                # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åã‚’ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã«å¤‰æ›
                possible_paths = [
                    f"{imp}.py",
                    f"{imp}/__init__.py",
                ]
                
                for path in possible_paths:
                    if Path(path).exists() and str(path) not in visited:
                        to_visit.append(str(path))
        
        return dependencies
    
    def generate_dependency_report(self):
        """ä¾å­˜é–¢ä¿‚ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        entry_points = self.find_entry_points()
        
        print("\n" + "=" * 80)
        print("ğŸ“Š å„ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆã®ä¾å­˜ãƒ•ã‚¡ã‚¤ãƒ«")
        print("=" * 80)
        
        all_used_files = set()
        
        for entry in entry_points:
            deps = self.trace_dependencies(entry)
            all_used_files.update(deps)
            
            print(f"\nğŸ“¦ {entry.name} ãŒä½¿ç”¨ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«:")
            for dep in sorted(deps)[:10]:  # æœ€åˆã®10å€‹
                print(f"  - {dep}")
            if len(deps) > 10:
                print(f"  ... ä»– {len(deps) - 10} ãƒ•ã‚¡ã‚¤ãƒ«")
        
        # ä½¿ã‚ã‚Œã¦ã„ãªã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œå‡º
        print("\n" + "=" * 80)
        print("ğŸ—‘ï¸ ä½¿ã‚ã‚Œã¦ã„ãªã„å¯èƒ½æ€§ã®ã‚ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«")
        print("=" * 80)
        
        all_files = set(str(f) for f in self.root.rglob("*.py") if '__pycache__' not in str(f))
        unused = all_files - all_used_files
        
        if unused:
            for file in sorted(list(unused))[:20]:  # æœ€åˆã®20å€‹
                print(f"  - {file}")
            if len(unused) > 20:
                print(f"  ... ä»– {len(unused) - 20} ãƒ•ã‚¡ã‚¤ãƒ«")
        else:
            print("âœ… å…¨ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒä½¿ç”¨ã•ã‚Œã¦ã„ã¾ã™")
        
        return {
            'used_files': list(all_used_files),
            'unused_files': list(unused)
        }

if __name__ == "__main__":
    tracker = ImportTracker()
    tracker.scan_project()
    report = tracker.generate_dependency_report()
    
    # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
    import json
    with open('dependency_report.json', 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    print("\nğŸ’¾ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã‚’ dependency_report.json ã«ä¿å­˜ã—ã¾ã—ãŸ")
