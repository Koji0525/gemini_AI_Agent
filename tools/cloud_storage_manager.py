# cloud_storage_manager.py
"""
ã‚¯ãƒ©ã‚¦ãƒ‰ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ãƒžãƒãƒ¼ã‚¸ãƒ£ãƒ¼
ãƒ­ãƒ¼ã‚«ãƒ«ã¨ã‚¯ãƒ©ã‚¦ãƒ‰ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã®é€éŽçš„ãªé€£æº
"""

import asyncio
import logging
import os
import json
from typing import Dict, Any, Optional, Union
from pathlib import Path
from datetime import datetime

logger = logging.getLogger(__name__)


class CloudStorageManager:
    """
    ã‚¯ãƒ©ã‚¦ãƒ‰ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ãƒžãƒãƒ¼ã‚¸ãƒ£ãƒ¼
    
    æ©Ÿèƒ½:
    - ãƒ­ãƒ¼ã‚«ãƒ«ã¨ã‚¯ãƒ©ã‚¦ãƒ‰ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã®é€éŽçš„ãªã‚¢ã‚¯ã‚»ã‚¹
    - è‡ªå‹•åŒæœŸ
    - ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç®¡ç†
    - è¤‡æ•°ã®ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼å¯¾å¿œ
    """
    
    def __init__(
        self,
        provider: str = "local",  # local, gcs, s3, azure
        bucket_name: Optional[str] = None,
        local_cache_dir: str = "./storage_cache",
        auto_sync: bool = True
    ):
        """
        åˆæœŸåŒ–
        
        Args:
            provider: ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼
            bucket_name: ãƒã‚±ãƒƒãƒˆ/ã‚³ãƒ³ãƒ†ãƒŠå
            local_cache_dir: ãƒ­ãƒ¼ã‚«ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            auto_sync: è‡ªå‹•åŒæœŸãƒ•ãƒ©ã‚°
        """
        self.provider = provider
        self.bucket_name = bucket_name
        self.local_cache_dir = Path(local_cache_dir)
        self.auto_sync = auto_sync
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        self.local_cache_dir.mkdir(parents=True, exist_ok=True)
        
        # ã‚¯ãƒ©ã‚¦ãƒ‰ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
        self.client = None
        self.bucket = None
        
        # çµ±è¨ˆæƒ…å ±
        self.stats = {
            "uploads": 0,
            "downloads": 0,
            "cache_hits": 0,
            "cache_misses": 0
        }
        
        # ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼åˆæœŸåŒ–
        if provider != "local":
            self._init_cloud_provider()
        
        logger.info(f"âœ… CloudStorageManager åˆæœŸåŒ–å®Œäº† (provider={provider})")
    
    def _init_cloud_provider(self):
        """ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚’åˆæœŸåŒ–"""
        try:
            if self.provider == "gcs":
                self._init_gcs()
            elif self.provider == "s3":
                self._init_s3()
            elif self.provider == "azure":
                self._init_azure()
            else:
                logger.warning(f"âš ï¸ æœªã‚µãƒãƒ¼ãƒˆã®ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼: {self.provider}")
        
        except Exception as e:
            logger.error(f"âŒ ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            logger.warning("âš ï¸ ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ¼ãƒ‰ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯")
            self.provider = "local"
    
    def _init_gcs(self):
        """Google Cloud StorageåˆæœŸåŒ–"""
        try:
            from google.cloud import storage
            self.client = storage.Client()
            self.bucket = self.client.bucket(self.bucket_name)
            logger.info(f"âœ… GCS ãƒã‚±ãƒƒãƒˆæŽ¥ç¶š: {self.bucket_name}")
        except ImportError:
            logger.error("âŒ google-cloud-storage ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            raise
    
    def _init_s3(self):
        """AWS S3åˆæœŸåŒ–"""
        try:
            import boto3
            self.client = boto3.client('s3')
            self.bucket_name = self.bucket_name
            logger.info(f"âœ… S3 ãƒã‚±ãƒƒãƒˆæŽ¥ç¶š: {self.bucket_name}")
        except ImportError:
            logger.error("âŒ boto3 ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            raise
    
    def _init_azure(self):
        """Azure Blob StorageåˆæœŸåŒ–"""
        try:
            from azure.storage.blob import BlobServiceClient
            connection_string = os.getenv("AZURE_STORAGE_CONNECTION_STRING")
            self.client = BlobServiceClient.from_connection_string(connection_string)
            self.bucket = self.client.get_container_client(self.bucket_name)
            logger.info(f"âœ… Azure ã‚³ãƒ³ãƒ†ãƒŠæŽ¥ç¶š: {self.bucket_name}")
        except ImportError:
            logger.error("âŒ azure-storage-blob ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            raise
    
    # ========================================
    # åŸºæœ¬æ“ä½œï¼ˆé€éŽçš„APIï¼‰
    # ========================================
    
    async def read_file(
        self, 
        file_path: str,
        encoding: Optional[str] = 'utf-8'
    ) -> Union[str, bytes]:
        """
        ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«/ã‚¯ãƒ©ã‚¦ãƒ‰é€éŽçš„ï¼‰
        
        Args:
            file_path: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            encoding: ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆNoneã®å ´åˆã¯ãƒã‚¤ãƒŠãƒªï¼‰
            
        Returns:
            Union[str, bytes]: ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹
        """
        try:
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
            cached_path = self._get_cache_path(file_path)
            
            if cached_path.exists():
                self.stats["cache_hits"] += 1
                logger.debug(f"ðŸ“¦ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆ: {file_path}")
                
                if encoding:
                    return await asyncio.to_thread(
                        cached_path.read_text,
                        encoding=encoding
                    )
                else:
                    return await asyncio.to_thread(cached_path.read_bytes)
            
            self.stats["cache_misses"] += 1
            
            # ã‚¯ãƒ©ã‚¦ãƒ‰ã‹ã‚‰èª­ã¿è¾¼ã¿
            if self.provider != "local":
                content = await self._download_from_cloud(file_path)
                
                # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
                if self.auto_sync:
                    await self._save_to_cache(file_path, content)
                
                if encoding and isinstance(content, bytes):
                    return content.decode(encoding)
                return content
            
            # ãƒ­ãƒ¼ã‚«ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿
            local_path = Path(file_path)
            if encoding:
                return await asyncio.to_thread(
                    local_path.read_text,
                    encoding=encoding
                )
            else:
                return await asyncio.to_thread(local_path.read_bytes)
            
        except Exception as e:
            logger.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {file_path} - {e}")
            raise
    
    async def write_file(
        self,
        file_path: str,
        content: Union[str, bytes],
        encoding: Optional[str] = 'utf-8'
    ):
        """
        ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›¸ãè¾¼ã¿ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«/ã‚¯ãƒ©ã‚¦ãƒ‰é€éŽçš„ï¼‰
        
        Args:
            file_path: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            content: æ›¸ãè¾¼ã‚€å†…å®¹
            encoding: ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
        """
        try:
            # ãƒ­ãƒ¼ã‚«ãƒ«ã«æ›¸ãè¾¼ã¿
            local_path = Path(file_path)
            local_path.parent.mkdir(parents=True, exist_ok=True)
            
            if isinstance(content, str):
                await asyncio.to_thread(
                    local_path.write_text,
                    content,
                    encoding=encoding
                )
            else:
                await asyncio.to_thread(local_path.write_bytes, content)
            
            # ã‚¯ãƒ©ã‚¦ãƒ‰ã«åŒæœŸ
            if self.provider != "local" and self.auto_sync:
                await self._upload_to_cloud(file_path, content)
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ›´æ–°
            await self._save_to_cache(file_path, content)
            
            logger.debug(f"âœ… ãƒ•ã‚¡ã‚¤ãƒ«æ›¸ãè¾¼ã¿æˆåŠŸ: {file_path}")
            
        except Exception as e:
            logger.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«æ›¸ãè¾¼ã¿ã‚¨ãƒ©ãƒ¼: {file_path} - {e}")
            raise
    
    async def file_exists(self, file_path: str) -> bool:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª"""
        try:
            # ãƒ­ãƒ¼ã‚«ãƒ«ãƒã‚§ãƒƒã‚¯
            if Path(file_path).exists():
                return True
            
            # ã‚¯ãƒ©ã‚¦ãƒ‰ãƒã‚§ãƒƒã‚¯
            if self.provider != "local":
                return await self._exists_in_cloud(file_path)
            
            return False
            
        except Exception as e:
            logger.error(f"âŒ å­˜åœ¨ç¢ºèªã‚¨ãƒ©ãƒ¼: {file_path} - {e}")
            return False
    
    async def delete_file(self, file_path: str):
        """ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤"""
        try:
            # ãƒ­ãƒ¼ã‚«ãƒ«å‰Šé™¤
            local_path = Path(file_path)
            if local_path.exists():
                await asyncio.to_thread(local_path.unlink)
            
            # ã‚¯ãƒ©ã‚¦ãƒ‰å‰Šé™¤
            if self.provider != "local":
                await self._delete_from_cloud(file_path)
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥å‰Šé™¤
            cached_path = self._get_cache_path(file_path)
            if cached_path.exists():
                await asyncio.to_thread(cached_path.unlink)
            
            logger.debug(f"âœ… ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤æˆåŠŸ: {file_path}")
            
        except Exception as e:
            logger.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {file_path} - {e}")
            raise
    
    # ========================================
    # ã‚¯ãƒ©ã‚¦ãƒ‰æ“ä½œï¼ˆãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼åˆ¥ï¼‰
    # ========================================
    
    async def _download_from_cloud(self, file_path: str) -> bytes:
        """ã‚¯ãƒ©ã‚¦ãƒ‰ã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
        self.stats["downloads"] += 1
        
        if self.provider == "gcs":
            return await self._download_from_gcs(file_path)
        elif self.provider == "s3":
            return await self._download_from_s3(file_path)
        elif self.provider == "azure":
            return await self._download_from_azure(file_path)
        else:
            raise ValueError(f"Unsupported provider: {self.provider}")
    
    async def _upload_to_cloud(self, file_path: str, content: Union[str, bytes]):
        """ã‚¯ãƒ©ã‚¦ãƒ‰ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"""
        self.stats["uploads"] += 1
        
        if isinstance(content, str):
            content = content.encode('utf-8')
        
        if self.provider == "gcs":
            await self._upload_to_gcs(file_path, content)
        elif self.provider == "s3":
            await self._upload_to_s3(file_path, content)
        elif self.provider == "azure":
            await self._upload_to_azure(file_path, content)
    
    async def _exists_in_cloud(self, file_path: str) -> bool:
        """ã‚¯ãƒ©ã‚¦ãƒ‰ã§ã®å­˜åœ¨ç¢ºèª"""
        if self.provider == "gcs":
            return await self._exists_in_gcs(file_path)
        elif self.provider == "s3":
            return await self._exists_in_s3(file_path)
        elif self.provider == "azure":
            return await self._exists_in_azure(file_path)
        return False
    
    async def _delete_from_cloud(self, file_path: str):
        """ã‚¯ãƒ©ã‚¦ãƒ‰ã‹ã‚‰å‰Šé™¤"""
        if self.provider == "gcs":
            await self._delete_from_gcs(file_path)
        elif self.provider == "s3":
            await self._delete_from_s3(file_path)
        elif self.provider == "azure":
            await self._delete_from_azure(file_path)
    
    # ========================================
    # GCSæ“ä½œ
    # ========================================
    
    async def _download_from_gcs(self, file_path: str) -> bytes:
        """GCSã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
        blob = self.bucket.blob(file_path)
        return await asyncio.to_thread(blob.download_as_bytes)
    
    async def _upload_to_gcs(self, file_path: str, content: bytes):
        """GCSã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"""
        blob = self.bucket.blob(file_path)
        await asyncio.to_thread(blob.upload_from_string, content)
    
    async def _exists_in_gcs(self, file_path: str) -> bool:
        """GCSã§ã®å­˜åœ¨ç¢ºèª"""
        blob = self.bucket.blob(file_path)
        return await asyncio.to_thread(blob.exists)
    
    async def _delete_from_gcs(self, file_path: str):
        """GCSã‹ã‚‰å‰Šé™¤"""
        blob = self.bucket.blob(file_path)
        await asyncio.to_thread(blob.delete)
    
    # ========================================
    # S3æ“ä½œ
    # ========================================
    
    async def _download_from_s3(self, file_path: str) -> bytes:
        """S3ã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
        response = await asyncio.to_thread(
            self.client.get_object,
            Bucket=self.bucket_name,
            Key=file_path
        )
        return response['Body'].read()
    
    async def _upload_to_s3(self, file_path: str, content: bytes):
        """S3ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"""
        await asyncio.to_thread(
            self.client.put_object,
            Bucket=self.bucket_name,
            Key=file_path,
            Body=content
        )
    
    async def _exists_in_s3(self, file_path: str) -> bool:
        """S3ã§ã®å­˜åœ¨ç¢ºèª"""
        try:
            await asyncio.to_thread(
                self.client.head_object,
                Bucket=self.bucket_name,
                Key=file_path
            )
            return True
        except:
            return False
    
    async def _delete_from_s3(self, file_path: str):
        """S3ã‹ã‚‰å‰Šé™¤"""
        await asyncio.to_thread(
            self.client.delete_object,
            Bucket=self.bucket_name,
            Key=file_path
        )
    
    # ========================================
    # Azureæ“ä½œ
    # ========================================
    
    async def _download_from_azure(self, file_path: str) -> bytes:
        """Azureã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
        blob_client = self.bucket.get_blob_client(file_path)
        return await asyncio.to_thread(blob_client.download_blob().readall)
    
    async def _upload_to_azure(self, file_path: str, content: bytes):
        """Azureã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"""
        blob_client = self.bucket.get_blob_client(file_path)
        await asyncio.to_thread(blob_client.upload_blob, content, overwrite=True)
    
    async def _exists_in_azure(self, file_path: str) -> bool:
        """Azureã§ã®å­˜åœ¨ç¢ºèª"""
        blob_client = self.bucket.get_blob_client(file_path)
        return await asyncio.to_thread(blob_client.exists)
    
    async def _delete_from_azure(self, file_path: str):
        """Azureã‹ã‚‰å‰Šé™¤"""
        blob_client = self.bucket.get_blob_client(file_path)
        await asyncio.to_thread(blob_client.delete_blob)
    
    # ========================================
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç®¡ç†
    # ========================================
    
    def _get_cache_path(self, file_path: str) -> Path:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‘ã‚¹ã‚’å–å¾—"""
        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ãƒ‘ã‚¹ã«å¤‰æ›
        safe_path = file_path.replace("/", "_").replace("\\", "_")
        return self.local_cache_dir / safe_path
    
    async def _save_to_cache(self, file_path: str, content: Union[str, bytes]):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜"""
        try:
            cached_path = self._get_cache_path(file_path)
            
            if isinstance(content, str):
                await asyncio.to_thread(
                    cached_path.write_text,
                    content,
                    encoding='utf-8'
                )
            else:
                await asyncio.to_thread(cached_path.write_bytes, content)
            
        except Exception as e:
            logger.warning(f"âš ï¸ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜å¤±æ•—: {file_path} - {e}")
    
    async def clear_cache(self):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢"""
        try:
            for cache_file in self.local_cache_dir.glob("*"):
                await asyncio.to_thread(cache_file.unlink)
            
            logger.info("âœ… ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢å®Œäº†")
            
        except Exception as e:
            logger.error(f"âŒ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢ã‚¨ãƒ©ãƒ¼: {e}")
    
    def get_stats(self) -> Dict[str, Any]:
        """çµ±è¨ˆæƒ…å ±ã‚’å–å¾—"""
        cache_hit_rate = 0.0
        total_cache_ops = self.stats["cache_hits"] + self.stats["cache_misses"]
        
        if total_cache_ops > 0:
            cache_hit_rate = self.stats["cache_hits"] / total_cache_ops
        
        return {
            **self.stats,
            "cache_hit_rate": cache_hit_rate,
            "provider": self.provider
        }